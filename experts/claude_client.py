"""Claude Worker - Code review/improve + Sanity check via Anthropic SDK."""
import os
import time

import anthropic

CLAUDE_MODEL = "claude-sonnet-4-20250514"
MAX_RETRIES = 2
TIMEOUT_SECONDS = 30

_client = None


def get_client():
    global _client
    if _client is None:
        key = os.getenv("ANTHROPIC_API_KEY")
        if not key:
            raise ValueError("ANTHROPIC_API_KEY not set in .env")
        _client = anthropic.Anthropic(
            api_key=key,
            timeout=TIMEOUT_SECONDS,
            max_retries=MAX_RETRIES,
        )
    return _client


def review_and_improve_code(code_text: str, user_request: str) -> str:
    """P4: Gemini generates code draft → Claude reviews and improves it."""
    client = get_client()
    start = time.time()

    response = client.messages.create(
        model=CLAUDE_MODEL,
        max_tokens=4096,
        messages=[
            {
                "role": "user",
                "content": (
                    f"Original user request:\n{user_request}\n\n"
                    f"Draft code (generated by another model):\n```\n{code_text}\n```\n\n"
                    "Review the draft code. Fix bugs, improve clarity and correctness. "
                    "Return ONLY the final improved code with brief inline comments where needed. "
                    "No extra explanation outside the code."
                ),
            }
        ],
    )

    latency_ms = int((time.time() - start) * 1000)
    print(f"Claude model used: {CLAUDE_MODEL} | latency: {latency_ms}ms")

    result = response.content[0].text if response.content else ""
    return result.strip()


def sanity_check_answer(
    draft_answer: str,
    user_request: str,
    sources_text: str | None = None,
) -> str:
    """P3: Gemini generates high-risk answer → Claude sanity-checks it."""
    client = get_client()
    start = time.time()

    sources_block = ""
    if sources_text:
        sources_block = f"\n\nSources provided:\n{sources_text}"

    response = client.messages.create(
        model=CLAUDE_MODEL,
        max_tokens=4096,
        messages=[
            {
                "role": "user",
                "content": (
                    f"Original user request:\n{user_request}\n\n"
                    f"Draft answer (generated by another model):\n{draft_answer}"
                    f"{sources_block}\n\n"
                    "You are a sanity/consistency checker. "
                    "Verify factual accuracy, flag contradictions, and fix errors. "
                    "Return the final corrected answer in the same language as the draft. "
                    "If the draft is correct, return it as-is. "
                    "No meta-commentary — only the final answer text."
                ),
            }
        ],
    )

    latency_ms = int((time.time() - start) * 1000)
    print(f"Claude model used: {CLAUDE_MODEL} | latency: {latency_ms}ms")

    result = response.content[0].text if response.content else ""
    return result.strip()
